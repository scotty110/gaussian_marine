{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Model Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not mean to be a rigurous training regiment, but rather a simple exploration of how to build a model, and plug in everything. More Complicated model training will come later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pyro\n",
    "import pyro.contrib.gp as gp\n",
    "\n",
    "from utils import partition_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE=torch.device('cpu') #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DTYPE=torch.float32\n",
    "\n",
    "pyro.set_rng_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data that was process by the `data_explore.ipynb`. This created a snappy.parquet file that stored all the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "marine_data = '/home/squirt/Documents/data/ncei/marine/marine_data/marine_climate_data.snappy.parquet'\n",
    "marine_df = pd.read_parquet(marine_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally wanted to subsample data, but just going to load all of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = partition_df(marine_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[['WindSpeed','WetTemp','SeaTemp','CloudAmount']].values\n",
    "y = train_df[['AirTemp']].values\n",
    "\n",
    "X = torch.tensor(X).to(DEVICE, dtype=DTYPE)\n",
    "y = torch.tensor(y).to(DEVICE, dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval = test_df[['WindSpeed','WetTemp','SeaTemp','CloudAmount']].values\n",
    "y_eval = test_df[['AirTemp']].values\n",
    "\n",
    "X_eval = torch.tensor(X_eval).to(DEVICE, dtype=DTYPE)\n",
    "y_eval = torch.tensor(y_eval).to(DEVICE, dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([34435, 4])\ty shape: torch.Size([34435, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f'X shape: {X.shape}\\ty shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to dig deeper into gaussian models, lets try pyro. [Link](https://pyro.ai/examples/gp.html) \n",
    "\n",
    "At some point create one from scratch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create search space for hyperparameters. Going to search from 0.001 to 100 taking log steps. No idea what our data will look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_search_space = torch.logspace(-3, 2, steps=10)  \n",
    "lengthscale_search_space = torch.logspace(-3, 2, steps=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = pyro.infer.Trace_ELBO().differentiable_loss\n",
    "results = {}\n",
    "y = y.squeeze(-1)\n",
    "for variance in variance_search_space:\n",
    "    for lengthscale in lengthscale_search_space:\n",
    "        # Set the hyperparameters\n",
    "        kernel = gp.kernels.RBF(input_dim=4, variance=variance, lengthscale=lengthscale)\n",
    "        gpr = gp.models.GPRegression(X, y, kernel, noise=torch.tensor(0.1), jitter=1.0e-4)\n",
    "        gpr = gpr.to(DEVICE, dtype=DTYPE)\n",
    "\n",
    "        optimizer = torch.optim.Adam(gpr.parameters(), lr=0.005)\n",
    "        losses = []\n",
    "        for i in range(30):\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(gpr.model, gpr.guide)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        results[(variance, lengthscale)] = losses\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Training Plots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
