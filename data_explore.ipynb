{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Marine Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to explore [NCEI Data](https://www.ncei.noaa.gov/cdo-web/datasets), specifically the [marine](https://www.ncei.noaa.gov/data/global-marine/) dataset. What is in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the scripts in the data dir to download the data. Run `aria2c -i urls.txt` to download the data. Decompress with the `.sh` script. You will need to make dir's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "marine_dir = \"/home/squirt/Documents/data/ncei/marine/marine_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load into duckdb\n",
    "\n",
    "Data columns in sample are not the same in the real data. WTF. Im also not sure if these CSV columns are the same accross all csvs?? Lol. The real world is messy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv_columns = [\"STATION\", \"DATE\", \"LATITUDE\", \"LONGITUDE\", \"ELEVATION\", \"NAME\", \"IMMA_VER\", \"ATTM_CT\", \"TIME_IND\", \"LL_IND\", \"SHIP_COURSE\", \"SHIP_SPD\", \"ID_IND\", \"COUNTRY_CODE\", \"WIND_DIR_IND\", \"WIND_DIR\", \"WIND_SPD_IND\", \"WIND_SPEED\", \"VV_IND\", \"VISIBILITY\", \"PRES_WX\", \"PAST_WX\", \"SEA_LVL_PRES\", \"CHAR_PPP\", \"AMT_PRES_TEND\", \"IND_FOR_TEMP\", \"AIR_TEMP\", \"IND_FOR_WBT\", \"WET_BULB_TEMP\", \"DPT_IND\", \"DEW_PT_TEMP\", \"SST_MM\", \"SEA_SURF_TEMP\", \"TOT_CLD_AMT\", \"LOW_CLD_AMT\", \"LOW_CLD_TYPE\", \"HGT_IND\", \"CLD_HGT\", \"MID_CLD_TYPE\", \"HI_CLD_TYPE\", \"WAVE_PERIOD\", \"WAVE_HGT\", \"SWELL_DIR\", \"SWELL_PERIOD\", \"SWELL_HGT\", \"TEN_BOX_NUM\", \"ONE_BOX_NUM\", \"DECK\", \"SOURCE_ID\", \"PLATFORM_ID\", \"DUP_STATUS\", \"DUP_CHK\", \"NIGHT_DAY_FLAG\", \"TRIM_FLAG\", \"NCDC_QC_FLAGS\", \"SOURCE_EXCLUSION_FLAG\", \"OB_SOURCE\", \"OB_PLATFORM\", \"FM_CODE_VER\", \"STA_WX_IND\", \"PAST_WX2\", \"DIR_OF_SWELL2\", \"PER_OF_SWELL2\", \"HGT_OF_SWELL2\", \"IND_FOR_PRECIP\", \"QC_IND\", \"QC_IND_FOR_FIELDS\", \"MQCS_VER\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make DuckDB table to store data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.DuckDBPyConnection at 0x749dff71e870>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = duckdb.connect(database=\":memory:\", read_only=False)\n",
    "table_name = 'marine_climate_data'\n",
    "\n",
    "# Create DuckDB table\n",
    "table_columns = \"Station VARCHAR, Time DATETIME, Lat DOUBLE, Lon DOUBLE, WindSpeed DOUBLE, AirTemp DOUBLE, WetTemp DOUBLE, SeaTemp DOUBLE, CloudAmount DOUBLE\"\n",
    "conn.execute(f\"CREATE TABLE {table_name} ({table_columns})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in CSV Columns to DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get CSV files\n",
    "csv_files = glob.glob(marine_dir + \"*.csv\")\n",
    "\n",
    "# Need to map the CSV columns to the DuckDB table columns\n",
    "csv_columns = [\"STATION\", \"DATE\", \"LATITUDE\", \"LONGITUDE\", \"WIND_SPEED\", \"AIR_TEMP\", \"WET_BULB_TEMP\", \"SEA_SURF_TEMP\", \"TOT_CLD_AMT\"] \n",
    "temp_table = 'temp_table'\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    # Create a temporary table from the CSV file\n",
    "    conn.execute(f\"CREATE TABLE {temp_table} AS SELECT * FROM read_csv_auto('{csv_file}')\")\n",
    "\n",
    "    # Drop table if columns not present (because I don't really understand this data)\n",
    "    # Fetch the column names from the table\n",
    "    table_info = conn.execute(f\"PRAGMA table_info({temp_table})\").fetchall()\n",
    "    temp_table_columns = [column[1] for column in table_info]\n",
    "\n",
    "    # Compare the table's columns with the csv_columns list\n",
    "    if set(csv_columns) - set(temp_table_columns):\n",
    "        # Drop the table if the columns don't match\n",
    "        conn.execute(f\"DROP TABLE IF EXISTS {temp_table}\")\n",
    "    else:\n",
    "        # Insert data from temporary table into final table with column mapping and type conversion\n",
    "        query = f\"\"\"\n",
    "        INSERT INTO {table_name} (Station, Time, Lat, Lon, WindSpeed, AirTemp, WetTemp, SeaTemp, CloudAmount)\n",
    "        SELECT \n",
    "            STATION, \n",
    "            TRY_CAST(REPLACE(DATE, 'T', ' ') AS DATETIME), \n",
    "            CAST(LATITUDE AS DOUBLE), \n",
    "            CAST(LONGITUDE AS DOUBLE), \n",
    "            CAST(WIND_SPEED AS DOUBLE), \n",
    "            CAST(AIR_TEMP AS DOUBLE), \n",
    "            CAST(WET_BULB_TEMP AS DOUBLE), \n",
    "            CAST(SEA_SURF_TEMP AS DOUBLE), \n",
    "            CAST(TOT_CLD_AMT AS DOUBLE)\n",
    "        FROM {temp_table}\n",
    "        \"\"\"\n",
    "        conn.execute(query)\n",
    "    \n",
    "        # Drop the temporary table after all CSV files have been imported\n",
    "        conn.execute(f\"DROP TABLE {temp_table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify data was ingested print out the count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(511470,)]\n"
     ]
    }
   ],
   "source": [
    "print(conn.execute(f\"SELECT COUNT(*) FROM {table_name}\").fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just want to peak at the data to see what were working with, can we train a gaussian process???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull record from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Station                Time    Lat     Lon  WindSpeed  AirTemp  WetTemp  \\\n",
      "0   52841 2000-03-01 03:19:00  10.74  163.21        NaN      NaN      NaN   \n",
      "1   52841 2000-03-01 05:03:00  10.74  163.21        NaN      NaN      NaN   \n",
      "2   52841 2000-03-01 06:39:00  10.74  163.21        NaN      NaN      NaN   \n",
      "3   52841 2000-03-01 07:56:00  10.79  163.00        NaN      NaN      NaN   \n",
      "4   52841 2000-03-01 09:27:00  10.74  163.21        NaN      NaN      NaN   \n",
      "\n",
      "   SeaTemp  CloudAmount  \n",
      "0    281.0          NaN  \n",
      "1    281.0          NaN  \n",
      "2    281.0          NaN  \n",
      "3    281.0          NaN  \n",
      "4    280.0          NaN  \n"
     ]
    }
   ],
   "source": [
    "df = conn.execute(f\"SELECT * FROM {table_name} LIMIT 10;\").fetchdf()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to predict AirTemp, so drop all Nulls??? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.DuckDBPyConnection at 0x749dff71e870>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute(f\"DELETE FROM {table_name} WHERE AirTemp IS NULL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many records are left?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(308269,)]\n"
     ]
    }
   ],
   "source": [
    "print(conn.execute(f\"SELECT COUNT(*) FROM {table_name}\").fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that looks like enough data for a simple model, again the goal is not to build the best model, but get familiar with gaussian processes.\n",
    "\n",
    "What does the data look like now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Station                Time   Lat    Lon  WindSpeed  AirTemp  WetTemp  \\\n",
      "0     WHRN 2000-03-03 18:00:00  19.8  167.9        5.0    244.0    222.0   \n",
      "1     WHRN 2000-03-04 00:00:00  19.3  165.1       77.0    244.0    227.0   \n",
      "2     WHRN 2000-03-04 06:00:00  18.8  163.2      113.0    244.0    217.0   \n",
      "3     KIRH 2000-03-04 12:00:00  19.2  168.8      129.0    250.0    239.0   \n",
      "4     WHRN 2000-03-04 12:00:00  18.2  160.7      118.0    233.0    216.0   \n",
      "5     KIRH 2000-03-05 00:00:00  18.3  164.1      129.0    300.0    256.0   \n",
      "6     WCPU 2000-03-08 18:00:00  19.9  163.5       26.0    250.0    226.0   \n",
      "7     WCPU 2000-03-09 00:00:00  19.8  161.0       36.0    283.0    261.0   \n",
      "8     HPEW 2000-03-11 00:00:00  14.9  161.1       98.0    280.0    260.0   \n",
      "9     WPGK 2000-03-11 11:00:00  19.2  169.1       36.0    261.0    244.0   \n",
      "10    HPEW 2000-03-11 12:00:00  12.9  163.1      103.0    260.0    240.0   \n",
      "11    WPGK 2000-03-11 18:00:00  18.7  166.3       26.0    256.0    244.0   \n",
      "12    WPGK 2000-03-12 00:00:00  18.3  164.0       57.0    294.0    272.0   \n",
      "13    KGTH 2000-03-16 18:00:00  19.5  163.3       82.0    150.0    150.0   \n",
      "14    WFLH 2000-03-18 18:00:00  19.0  167.9        0.0    250.0    217.0   \n",
      "15    WFLH 2000-03-19 00:00:00  18.6  165.6       26.0    272.0    233.0   \n",
      "16    WFLH 2000-03-19 06:00:00  18.2  163.5       26.0    289.0    244.0   \n",
      "17    WFLH 2000-03-19 12:00:00  17.7  161.1       51.0    250.0    228.0   \n",
      "18   ELOF4 2000-03-23 06:00:00  12.1  160.5       87.0    310.0    260.0   \n",
      "19   C6FE3 2000-03-23 12:00:00  12.3  163.1       93.0    290.0    245.0   \n",
      "\n",
      "    SeaTemp  CloudAmount  \n",
      "0     283.0          4.0  \n",
      "1     283.0          7.0  \n",
      "2     283.0          8.0  \n",
      "3     261.0          6.0  \n",
      "4     283.0          4.0  \n",
      "5     261.0          6.0  \n",
      "6       NaN          1.0  \n",
      "7       NaN          2.0  \n",
      "8     262.0          3.0  \n",
      "9     272.0          2.0  \n",
      "10    275.0          2.0  \n",
      "11    272.0          2.0  \n",
      "12    272.0          3.0  \n",
      "13      NaN          7.0  \n",
      "14    272.0          2.0  \n",
      "15    272.0          2.0  \n",
      "16    278.0          3.0  \n",
      "17    278.0          2.0  \n",
      "18    300.0          2.0  \n",
      "19    290.0          2.0  \n"
     ]
    }
   ],
   "source": [
    "df = conn.execute(f\"SELECT * FROM {table_name} LIMIT 20;\").fetchdf()\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data looks good! Surprising. I think we can train a very simple model on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we can now build a data loader with this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.DuckDBPyConnection at 0x749dff71e870>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = f'{marine_dir}/marine_climate_data.snappy.parquet'\n",
    "conn.execute(f\"COPY (SELECT * FROM {table_name}) TO '{save_path}' (FORMAT 'parquet', CODEC 'snappy')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
